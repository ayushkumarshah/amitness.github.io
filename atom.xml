<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Amit Chaudhary</title><link href="https://amitness.com/" rel="alternate"></link><link href="https://amitness.com/atom.xml" rel="self"></link><id>https://amitness.com/</id><updated>2020-03-04T10:00:00+05:45</updated><entry><title>The Illustrated SimCLRÂ Framework</title><link href="https://amitness.com/2020/03/illustrated-simclr/" rel="alternate"></link><published>2020-03-04T10:00:00+05:45</published><updated>2020-03-04T10:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2020-03-04:/2020/03/illustrated-simclr/</id><summary type="html">&lt;p&gt;A visual guide to the SimCLR framework for contrastive learning of visual&amp;nbsp;representations.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In recent years, &lt;a href="https://amitness.com/2020/02/illustrated-self-supervised-learning/"&gt;numerous self-supervised learning methods&lt;/a&gt; have been proposed for learning image representations, each getting better than the previous. But, their performance was still below the supervised counterparts. This changed when &lt;strong&gt;Chen et. al&lt;/strong&gt; proposed a new framework in their research paper &amp;#8220;&lt;a href="https://arxiv.org/abs/2002.05709"&gt;SimCLR: A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&amp;#8220;. The research paper not only improves upon the previous state-of-the-art self-supervised learning methods but also beats the supervised learning method on ImageNet&amp;nbsp;classification.&lt;/p&gt;
&lt;p&gt;In this article, I will explain the key ideas of the framework proposed in the research paper using&amp;nbsp;diagrams.&lt;/p&gt;
&lt;h2 id="the-nostalgic-intuition"&gt;The Nostalgic&amp;nbsp;Intuition&lt;/h2&gt;
&lt;p&gt;As a kid, I remember we had to solve such puzzles in our textbook.&lt;br&gt;
&lt;img alt="Find a Pair Exercise" class="img-center" src="/images/contrastive-find-a-pair.png"&gt;  &lt;br&gt;
The way a child would solve it is by looking at the picture of the animal on the left side, know its a cat, then search for a cat on the right side.&lt;br&gt;
&lt;img alt="Child Matching Animal Pairs" class="img-center" src="/images/contrastive-puzzle.gif"&gt;    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Such exercises were prepared for the child to be able to recognize an object and contrast that to other objects. Can we teach machines in a similar&amp;nbsp;manner?&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It turns out that we can through a technique called &lt;strong&gt;Contrastive Learning&lt;/strong&gt;. It attempts to teach machines to distinguish between similar and dissimilar things.
&lt;img alt="Contrastive Learning Block" class="img-center" src="/images/simclr-contrastive-learning.png"&gt;&lt;/p&gt;
&lt;h2 id="problem-formulation-for-machines"&gt;Problem Formulation for&amp;nbsp;Machines&lt;/h2&gt;
&lt;p&gt;To model the above exercise for a machine instead of a child, we see that we require 3&amp;nbsp;things:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Examples of similar and dissimilar images&lt;/strong&gt; &lt;br&gt;
We would require example pairs of images that are similar and images that are different for training a model.&lt;br&gt;
&lt;img alt="Pair of similar and dissimilar images" class="img-center" src="/images/contrastive-need-one.png"&gt;&lt;br&gt;
The supervised school of thought would require a human to manually create such pairs. To automate this, we could leverage &lt;a href="https://amitness.com/2020/02/illustrated-self-supervised-learning/"&gt;self-supervised learning&lt;/a&gt;. But how do we formulate it?
&lt;img alt="Manually Labeling pairs of Images" class="img-center" src="/images/contrastive-supervised-approach.png"&gt;&lt;br&gt;
&lt;img alt="Self-supervised Approach to Labeling Images" class="img-center" src="/images/contrastive-self-supervised-approach.png"&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ability to know what an image represents&lt;/strong&gt;&lt;br&gt;
We need some mechanism to get representations that allow the machine to understand an image.
&lt;img alt="Converting Image to Representations" class="img-center" src="/images/image-representation.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ability to quantify if two images are similar&lt;/strong&gt;&lt;br&gt;
We need some mechanism to compute the similarity of two images. 
&lt;img alt="Computing Similarity between Images" class="img-center" src="/images/image-similarity.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="the-simclr-framework-approach"&gt;The SimCLR Framework&amp;nbsp;Approach&lt;/h2&gt;
&lt;p&gt;The paper proposes a framework &amp;#8220;&lt;strong&gt;SimCLR&lt;/strong&gt;&amp;#8221; for modeling the above problem in a self-supervised manner. It blends the concept of &lt;em&gt;Contrastive Learning&lt;/em&gt; with a few novel ideas to learn visual representations without human&amp;nbsp;supervision. &lt;/p&gt;
&lt;h2 id="framework"&gt;Framework&lt;/h2&gt;
&lt;p&gt;The framework, as the full-form suggests, is very simple. An image is taken and random transformations are applied to it to get a pair of two augmented images &lt;tt class="math"&gt;x_i&lt;/tt&gt; and &lt;tt class="math"&gt;x_j&lt;/tt&gt;. Each image in that pair is passed through an encoder to get representations. Then a non-linear fully connected layer is applied to get representations z. The task is to maximize the similarity between these two representations &lt;tt class="math"&gt;z_i&lt;/tt&gt; and &lt;tt class="math"&gt;z_j&lt;/tt&gt; for the same image.
&lt;img alt="General Architecture of the SimCLR Framework" class="img-center" src="/images/simclr-general-architecture.png"&gt;&lt;/p&gt;
&lt;h2 id="step-by-step-example"&gt;Step by Step&amp;nbsp;Example&lt;/h2&gt;
&lt;p&gt;Let&amp;#8217;s explore the various components of the framework with an example. Suppose we have a training corpus of millions of unlabeled images.
&lt;img alt="Corpus of millions of images" class="img-center" src="/images/simclr-raw-data.png"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Self-supervised Formulation&lt;/strong&gt; [Data Augmentation]&lt;br&gt;
First, we generate batches of size N from the raw images. Let&amp;#8217;s take a batch of size N = 2 for simplicity. In the paper, they use a large batch size of 8192.
&lt;img alt="A single batch of images" class="img-center" src="/images/simclr-single-batch.png"&gt;  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The paper defines a random transformation function T that takes an image and applies a combination of &lt;code&gt;random (crop + flip + color jitter + grayscale)&lt;/code&gt;.
&lt;img alt="Random Augmentation on Image" class="img-center" src="/images/simclr-random-transformation-function.gif"&gt;  &lt;/p&gt;
&lt;p&gt;For each image in this batch, random transformation function is applied to get a pairs of 2 images. Thus, for a batch size of 2, we get 2*N = 2*2 = 4 total images.&lt;br&gt;
&lt;img alt="Augmenting images in a batch for SimCLR" class="img-center" src="/images/simclr-batch-data-preparation.png"&gt;&lt;br&gt;
2. &lt;strong&gt;Getting Representations&lt;/strong&gt; [Base&amp;nbsp;Encoder]  &lt;/p&gt;
&lt;p&gt;Each augmented image in a pair is passed through an encoder to get image representations. The encoder used is generic and replaceable with other architectures. The two encoders shown below have shared weights and we get vectors &lt;tt class="math"&gt;h_i&lt;/tt&gt; and &lt;tt class="math"&gt;h_j&lt;/tt&gt;.
&lt;img alt="Encoder part of SimCLR" class="img-center" src="/images/simclr-encoder-part.png"&gt;&lt;/p&gt;
&lt;p&gt;In the paper, the authors used &lt;a href="https://arxiv.org/abs/1512.03385"&gt;ResNet-50&lt;/a&gt; architecture as the ConvNet encoder. The output is a 2048-dimensional vector h.
&lt;img alt="ResNet-50 as encoder in SimCLR" class="img-center" src="/images/simclr-paper-encoder.png"&gt;
3. &lt;strong&gt;Projection Head&lt;/strong&gt;&lt;br&gt;
The representations &lt;tt class="math"&gt;h_i&lt;/tt&gt; and &lt;tt class="math"&gt;h_j&lt;/tt&gt; of the two augmented images are then passed through a series of non-linear &lt;strong&gt;Dense -&amp;gt; Relu -&amp;gt; Dense&lt;/strong&gt; layers to apply non-linear transformation and project it into a representation &lt;tt class="math"&gt;z_i&lt;/tt&gt; and &lt;tt class="math"&gt;z_j&lt;/tt&gt;. This is denoted by &lt;tt class="math"&gt;g(.)&lt;/tt&gt; in the paper and called projection head.
&lt;img alt="Projection Head Component of SimCLR" class="img-center" src="/images/simclr-projection-head-component.png"&gt;
4. &lt;strong&gt;Tuning Model&lt;/strong&gt;: [Bringing similar closer]&lt;br&gt;
Thus, for each augmented image in the batch, we get embedding vectors &lt;tt class="math"&gt;z&lt;/tt&gt; for it.
&lt;img alt="Projecting image to embedding vectors" class="img-center" src="/images/simclr-projection-vectors.png"&gt;&lt;/p&gt;
&lt;p&gt;From these embedding, we calculate the loss in following&amp;nbsp;steps:  &lt;/p&gt;
&lt;p&gt;a. &lt;strong&gt;Calculation of Cosine&amp;nbsp;Similarity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, the similarity between two augmented versions of an image is calculated using cosine similarity. For two augmented images &lt;tt class="math"&gt;x_i&lt;/tt&gt; and &lt;tt class="math"&gt;x_j&lt;/tt&gt;, the cosine similarity is calculated on its projected representations &lt;tt class="math"&gt;z_i&lt;/tt&gt; and &lt;tt class="math"&gt;z_j&lt;/tt&gt;.
&lt;img alt="Cosine similarity between image embeddings" class="img-center" src="/images/simclr-cosine-similarity.png"&gt;&lt;/p&gt;
&lt;pre class="math"&gt;
s_{i,j} = \frac{ \textcolor{#ff7070}{z_{i}^{T}z_{j}} }{(\tau ||\textcolor{#ff7070}{z_{i}}|| ||\textcolor{#ff7070}{z_{j}}||)}
&lt;/pre&gt;

&lt;p&gt;where   &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;tt class="math"&gt;\tau&lt;/tt&gt; is the adjustable temperature parameter. It can scale the inputs and widen the range [-1, 1] of cosine&amp;nbsp;similarity.  &lt;/li&gt;
&lt;li&gt;&lt;tt class="math"&gt;||z_{i}||&lt;/tt&gt; is the norm of the&amp;nbsp;vector&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pairwise cosine similarity between each augmented image in a batch is calculated using the above formula. As shown in the figure, in an ideal case, the similarities between augmented images of cats will be high while the similarity between cat and elephant images will be lower.
&lt;img alt="Pairwise cosine similarity between 4 images" class="img-center" src="/images/simclr-pairwise-similarity.png"&gt;&lt;/p&gt;
&lt;p&gt;b. &lt;strong&gt;Loss Calculation&lt;/strong&gt;&lt;br&gt;
SimCLR uses a contrastive loss called &amp;#8220;&lt;strong&gt;&lt;span class="caps"&gt;NT&lt;/span&gt;-Xent&lt;/strong&gt;&amp;#8221; (&lt;strong&gt;Normalized Temperature-Scaled Cross-Entropy Loss&lt;/strong&gt;). Let see intuitively how it&amp;nbsp;works.  &lt;/p&gt;
&lt;p&gt;First, the augmented pairs in the batch are taken one by one.
&lt;img alt="Example of a single batch in SimCLR" class="img-center" src="/images/simclr-augmented-pairs-batch.png"&gt;
Next, we apply the softmax function to get the probability of these two images being similar.&lt;br&gt;
&lt;img alt="Softmax Calculation on Image Similarities" src="/images/simclr-softmax-calculation.png"&gt;
This softmax calculation is equivalent to getting the probability of the second augmented cat image being the most similar to the first cat image in the pair. Here, all remaining images in the batch are sampled as dissimilar image (negative pair). Thus, we don&amp;#8217;t need specialized architecture, memory bank or queue need by previous approaches like &lt;a href="https://arxiv.org/pdf/1805.01978.pdf"&gt;InstDisc&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1911.05722"&gt;MoCo&lt;/a&gt; or &lt;a href="https://arxiv.org/abs/1912.01991"&gt;&lt;span class="caps"&gt;PIRL&lt;/span&gt;&lt;/a&gt; 
&lt;img alt="Interpretation of Softmax Function" class="img-center" src="/images/simclr-softmax-interpretation.png"&gt;&lt;/p&gt;
&lt;p&gt;Then, the loss is calculated for a pair by taking the negative of the log of above calculation. This formulation is the Noise Contrastive Estimation(&lt;span class="caps"&gt;NCE&lt;/span&gt;) Loss.
&lt;pre class="math"&gt;
l(i, j) = -log\frac{exp(s_{i, j})}{ \sum_{k=1}^{2N} l_{[k!= i]} exp(s_{i, k})}
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Calculation of Loss from softmax" src="/images/simclr-softmax-loss.png"&gt;&lt;/p&gt;
&lt;p&gt;We calculate the loss for the same pair a second time as well where the positions of the images are interchanged.
&lt;img alt="Calculation of loss for exchanged pairs of images" src="/images/simclr-softmax-loss-inverted.png"&gt;&lt;/p&gt;
&lt;p&gt;Finally, we compute loss over all the pairs in the batch of size N=2 and take an average.
&lt;pre class="math"&gt;
L = \frac{1}{ 2\textcolor{#2196f3}{N} } \sum_{k=1}^{N} [l(2k-1, 2k) + l(2k, 2k-1)]
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Total loss in SimCLR" src="/images/simclr-total-loss.png"&gt;&lt;/p&gt;
&lt;p&gt;Based on the loss, the encoder and projection head representations improves over time and the representations obtained place similar images closer in the&amp;nbsp;space.&lt;/p&gt;
&lt;h2 id="downstream-tasks"&gt;Downstream&amp;nbsp;Tasks&lt;/h2&gt;
&lt;p&gt;Once the model is trained on the contrastive learning task, it can be used for transfer learning. In this, the representations from the encoder are used instead of representations obtained from the projection head. These representations can be used for downstream tasks like  ImageNet Classification.
&lt;img alt="Using SimCLR for downstream tasks" src="/images/simclr-downstream.png"&gt;&lt;/p&gt;
&lt;h2 id="objective-results"&gt;Objective&amp;nbsp;Results&lt;/h2&gt;
&lt;p&gt;SimCLR outperformed previous self-supervised methods on ImageNet. The below image shows top-1 accuracy of linear classifiers trained on representations learned with different self-supervised methods on ImageNet. The gray cross is supervised ResNet50 and SimCLR is shown in bold.
&lt;img alt="Performance of SimCLR on ImageNet" class="img-center" src="/images/simclr-performance.png"&gt;
&lt;p class="has-text-centered"&gt;
Source: &lt;a href="https://arxiv.org/abs/2002.05709"&gt;SimCLR&amp;nbsp;paper&lt;/a&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On ImageNet &lt;a href="http://image-net.org/challenges/LSVRC/2012/"&gt;&lt;span class="caps"&gt;ILSVRC&lt;/span&gt;-2012&lt;/a&gt;, it achieves 76.5% top-1 accuracy which is 7% improvement over previous &lt;span class="caps"&gt;SOTA&lt;/span&gt; self-supervised method &lt;a href="https://arxiv.org/abs/1905.09272"&gt;Contrastive Predictive Coding&lt;/a&gt; and on-par with supervised&amp;nbsp;ResNet50.  &lt;/li&gt;
&lt;li&gt;When trained on 1% of labels, it achieves 85.8% top-5 accuracy outperforming AlexNet with 100x fewer&amp;nbsp;labels&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Thus, SimCLR provides a strong framework for doing further research in this direction and improve the state of self-supervised learning for Computer&amp;nbsp;Vision.&lt;/p&gt;
&lt;h2 id="citation-info-bibtex"&gt;Citation Info&amp;nbsp;(BibTex)&lt;/h2&gt;
&lt;p&gt;If you found this blog post useful, please consider citing it&amp;nbsp;as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@misc{chaudhary2020simclr,
  title   = {The Illustrated SimCLR Framework},
  author  = {Amit Chaudhary},
  year    = 2020,
  note    = {\url{https://amitness.com/2020/03/illustrated-simclr}}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2002.05709"&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;A Simple Framework for Contrastive Learning of Visual&amp;nbsp;Representations&amp;#8221;&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1706.04599.pdf"&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;On Calibration of Modern Neural&amp;nbsp;Networks&amp;#8221;&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1503.02531.pdf"&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Distilling the Knowledge in a Neural&amp;nbsp;Network&amp;#8221;&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>The Illustrated Self-SupervisedÂ Learning</title><link href="https://amitness.com/2020/02/illustrated-self-supervised-learning/" rel="alternate"></link><published>2020-02-25T03:00:00+05:45</published><updated>2020-02-25T03:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2020-02-25:/2020/02/illustrated-self-supervised-learning/</id><summary type="html">&lt;p&gt;A visual introduction to the patterns of problem formulation in self-supervised&amp;nbsp;learning.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yann Lecun, in his &lt;a href="https://www.youtube.com/watch?v=7I0Qt7GALVk&amp;amp;t=2639s"&gt;talk&lt;/a&gt;, introduced the &amp;#8220;cake analogy&amp;#8221; to illustrate the importance of self-supervised learning. Though the analogy is debated(&lt;a href="https://orfe.princeton.edu/~alaink/SmartDrivingCars/PDFs/2017_12_xx_NIPS-keynote-final.pdf"&gt;ref: Deep Learning for Robotics(Slide 96), Pieter Abbeel&lt;/a&gt;), we have seen the impact of self-supervised learning in the Natural Language Processing field where recent developments (Word2Vec, Glove, &lt;span class="caps"&gt;ELMO&lt;/span&gt;, &lt;span class="caps"&gt;BERT&lt;/span&gt;) have embraced self-supervision and achieved state of the art&amp;nbsp;results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âIf intelligence is a cake, the bulk of the cake is self-supervised learning, the icing on the cake is supervised learning, and the cherry on the cake is reinforcement learning (&lt;span class="caps"&gt;RL&lt;/span&gt;).â  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Curious to know how self-supervised learning has been applied in the computer vision field, I read up on existing literature on self-supervised learning applied to computer vision through a &lt;a href="https://arxiv.org/abs/1902.06162"&gt;recent survey paper&lt;/a&gt; by Jing et.&amp;nbsp;al. &lt;/p&gt;
&lt;p&gt;This post is my attempt to provide an intuitive visual summary of the patterns of problem formulation in self-supervised&amp;nbsp;learning.&lt;/p&gt;
&lt;h1 id="the-key-idea"&gt;The Key&amp;nbsp;Idea&lt;/h1&gt;
&lt;p&gt;To apply supervised learning, we need enough labeled data. To acquire that, human annotators manually label data(images/text) which is both a time consuming and expensive process. There are also fields such as the medical field where getting enough data is a challenge&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Manual Annotation in Supervised Learning" src="/images/supervised-manual-annotation.png"&gt;&lt;/p&gt;
&lt;p&gt;This is where self-supervised learning comes into play. It poses the following question to solve&amp;nbsp;this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we design the task in such a way that we can generate virtually unlimited labels from our existing images and use that to learn the&amp;nbsp;representations?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Automating manual labeling" class="img-center" src="/images/supervised-automated.png"&gt;&lt;/p&gt;
&lt;p&gt;We replace the human annotation block by creatively exploiting some property of data to set up a supervised task. For example, here instead of labeling images as cat/dog, we could instead rotate them by 0/90/180/270 degrees and train a model to predict rotation. We can generate virtually unlimited training data from millions of images we have freely available.
&lt;img alt="Self-supervised workflow diagram" class="img-center" src="/images/self-supervised-workflow.png"&gt;&lt;/p&gt;
&lt;h1 id="existing-creative-approaches"&gt;Existing Creative&amp;nbsp;Approaches&lt;/h1&gt;
&lt;p&gt;Below is a list of approaches various researchers have proposed to exploit image and video properties and learn representation in a self-supervised&amp;nbsp;manner.&lt;/p&gt;
&lt;h1 id="learning-from-images"&gt;Learning from&amp;nbsp;Images&lt;/h1&gt;
&lt;h2 id="1-image-colorization"&gt;1. &lt;strong&gt;Image&amp;nbsp;Colorization&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared pairs of (grayscale, colorized) images by applying grayscale to millions of images we have freely&amp;nbsp;available?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Data Generation for Image Colorization" class="img-center" src="/images/ss-colorization-data-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;We could use an encoder-decoder architecture based on a fully convolutional neural network and compute the L2 loss between the predicted and actual color&amp;nbsp;images.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Architecture for Image Colorization" class="img-center" src="/images/ss-image-colorization.png"&gt;    &lt;/p&gt;
&lt;p&gt;To solve this task, the model has to learn about different objects present in the image and related parts so that it can paint those parts in the same color. Thus, representations learned are useful for downstream tasks.
&lt;img alt="Learning to colorize images" class="img-center" src="/images/ss-colorization-learning.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers:&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1603.08511"&gt;Colorful Image Colorization&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/1705.02999"&gt;Real-Time User-Guided Image Colorization with Learned Deep Priors&lt;/a&gt; | &lt;a href="http://iizuka.cs.tsukuba.ac.jp/projects/colorization/en/"&gt;Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous&amp;nbsp;Classification&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="2-image-superresolution"&gt;2. &lt;strong&gt;Image&amp;nbsp;Superresolution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (small, upscaled) images by downsampling millions of images we have freely&amp;nbsp;available?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Superresolution" class="img-center" src="/images/ss-superresolution-training-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;GAN&lt;/span&gt; based models such as &lt;a href="https://arxiv.org/abs/1609.04802"&gt;&lt;span class="caps"&gt;SRGAN&lt;/span&gt;&lt;/a&gt; are popular for this task. A generator takes a low-resolution image and outputs a high-resolution image using a fully convolutional network. The actual and generated images are compared using both mean-squared-error and content loss to imitate human-like quality comparison. A binary-classification discriminator takes an image and classifies whether it&amp;#8217;s an actual high-resolution image(1) or a fake generated superresolution image(0). This interplay between the two models leads to generator learning to produce images with fine details. 
&lt;img alt="Architecture for SRGAN" class="img-center" src="/images/ss-srgan-architecture.png"&gt;  &lt;/p&gt;
&lt;p&gt;Both generator and discriminator learn semantic features that can be used for downstream&amp;nbsp;tasks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1609.04802"&gt;Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial&amp;nbsp;Network&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="3-image-inpainting"&gt;3. &lt;strong&gt;Image&amp;nbsp;Inpainting&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (corrupted, fixed) images by randomly removing part of&amp;nbsp;images?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Image Inpainting" class="img-center" src="/images/ss-image-inpainting-data-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;Similar to superresolution, we can leverage a &lt;span class="caps"&gt;GAN&lt;/span&gt;-based architecture where the Generator can learn to reconstruct the image while discriminator separates real and generated images.
&lt;img alt="Architecture for Image Inpainting" class="img-center" src="/images/ss-inpainting-architecture.png"&gt;  &lt;/p&gt;
&lt;p&gt;For downstream tasks, &lt;a href="https://arxiv.org/abs/1604.07379"&gt;Pathak et al.&lt;/a&gt; have shown that semantic features learned by such a generator give 10.2% improvement over random initialization on the &lt;a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html"&gt;&lt;span class="caps"&gt;PASCAL&lt;/span&gt; &lt;span class="caps"&gt;VOC&lt;/span&gt; 2012&lt;/a&gt; semantic segmentation challenge while giving &amp;lt;4% improvements over classification and object&amp;nbsp;detection.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1604.07379"&gt;Context encoders: Feature learning by&amp;nbsp;inpainting&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="4-image-jigsaw-puzzle"&gt;4. &lt;strong&gt;Image Jigsaw&amp;nbsp;Puzzle&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (shuffled, ordered) puzzles by randomly shuffling patches of&amp;nbsp;images?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data For Image Jigsaw Puzzle" class="img-center" src="/images/ss-image-jigsaw-data.png"&gt;  &lt;/p&gt;
&lt;p&gt;Even with only 9 patches, there can be 362880 possible puzzles. To overcome this, only a subset of possible permutations is used such as 64 permutations with the highest hamming distance.
&lt;img alt="Number of Permutations in Image Jigsaw" class="img-center" src="/images/ss-jigsaw-permutations.png"&gt;&lt;/p&gt;
&lt;p&gt;Suppose we use a permutation that changes the image as shown below. Let&amp;#8217;s use the permutation number 64 from our total available 64 permutations.
&lt;img alt="Example of single permutation in jigsaw" class="img-center" src="/images/ss-jigsaw-permutation-64.png"&gt;&lt;/p&gt;
&lt;p&gt;Now, to recover back the original patches, &lt;a href="https://arxiv.org/abs/1603.09246"&gt;Noroozi et al.&lt;/a&gt;
 proposed a neural network called context-free network (&lt;span class="caps"&gt;CFN&lt;/span&gt;) as shown below. Here, the individual patches are passed through the same siamese convolutional layers that have shared weights. Then, the features are combined in a fully-connected layer. In the output, the model has to predict which permutation was used from the 64 possible classes. If we know the permutation, we can solve the puzzle.
&lt;img alt="Architecture for Image Jigsaw Task" class="img-center" src="/images/ss-jigsaw-architecture.png"&gt;&lt;/p&gt;
&lt;p&gt;To solve the Jigsaw puzzle, the model needs to learn to identify how parts are assembled in an object, relative positions of different parts of objects and shape of objects. Thus, the representations are useful for downstream tasks in classification and&amp;nbsp;detection.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1603.09246"&gt;Unsupervised learning of visual representations by solving jigsaw&amp;nbsp;puzzles&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="5-context-prediction"&gt;5. &lt;strong&gt;Context&amp;nbsp;Prediction&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (image-patch, neighbor) by randomly taking an image patch and one of its neighbors around it from large, unlabeled image&amp;nbsp;collection?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Context Prediction" class="img-center" src="/images/ss-context-prediction-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;To solve this pre-text task, &lt;a href="https://arxiv.org/abs/1505.05192"&gt;Doersch et al.&lt;/a&gt; used an architecture similar to that of a jigsaw puzzle. We pass the patches through two siamese ConvNets to extract features, concatenate the features and do a classification over 8 classes denoting the 8 possible neighbor positions.
&lt;img alt="Architecture for Context Prediction" class="img-center" src="/images/ss-context-prediction-architecture.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1505.05192"&gt;Unsupervised Visual Representation Learning by Context&amp;nbsp;Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="6-geometric-transformation-recognition"&gt;6. &lt;strong&gt;Geometric Transformation&amp;nbsp;Recognition&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (rotated-image, rotation-angle) by randomly rotating images by (0, 90, 180, 270) from large, unlabeled image&amp;nbsp;collection?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Geometric Transformation" class="img-center" src="/images/ss-geometric-transformation-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;To solve this pre-text task, &lt;a href="https://arxiv.org/abs/1505.05192"&gt;Gidaris et al.&lt;/a&gt; propose an architecture where a rotated image is passed through a ConvNet and the network has to classify it into 4 classes(0/90/270/360 degrees).
&lt;img alt="Architecture for Geometric Transformation Predction" class="img-center" src="/images/ss-geometric-transformation-architecture.png"&gt;&lt;/p&gt;
&lt;p&gt;Though a very simple idea, the model has to understand location, types and pose of objects in an image to solve this task and as such, the representations learned are useful for downstream&amp;nbsp;tasks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1803.07728"&gt;Unsupervised Representation Learning by Predicting Image&amp;nbsp;Rotations&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="7-image-clustering"&gt;7. &lt;strong&gt;Image&amp;nbsp;Clustering&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (image, cluster-number) by performing clustering on large, unlabeled image&amp;nbsp;collection?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Image Clustering" class="img-center" src="/images/ss-image-clustering-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;To solve this pre-text task, &lt;a href="https://arxiv.org/abs/1807.05520"&gt;Caron et al.&lt;/a&gt; propose an architecture called deep clustering. Here, the images are first clustered and the clusters are used as classes. The task of the ConvNet is to predict the cluster label for an input image.
&lt;img alt="Architecture for Deep Clustering" class="img-center" src="/images/ss-deep-clustering-architecture.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1807.05520"&gt;Deep clustering for unsupervised learning of visual&amp;nbsp;features&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="8-synthetic-imagery"&gt;8. &lt;strong&gt;Synthetic&amp;nbsp;Imagery&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (image, properties) by generating synthetic images using game engines and adapting it to real&amp;nbsp;images?  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Sythetic Imagery" class="img-center" src="/images/synthetic-imagery-data.png"&gt;  &lt;/p&gt;
&lt;p&gt;To solve this pre-text task, &lt;a href="https://arxiv.org/pdf/1711.09082.pdf"&gt;Ren et al.&lt;/a&gt; propose an architecture where weight-shared ConvNets are trained on both synthetic and real images and then a discriminator learns to classify whether ConvNet features fed to it is of a synthetic image or a real image. Due to adversarial nature, the shared representations between real and synthetic images get better.
&lt;img alt="Architecture for Synthetic Image Training" class="img-center" src="/images/ss-synthetic-image-architecture.png"&gt;&lt;/p&gt;
&lt;h1 id="learning-from-videos"&gt;Learning from&amp;nbsp;Videos&lt;/h1&gt;
&lt;h2 id="1-frame-order-verification"&gt;1. &lt;strong&gt;Frame Order&amp;nbsp;Verification&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Formulation:   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if we prepared training pairs of (video frames, correct/incorrect order) by shuffling frames from videos of objects in&amp;nbsp;motion?   &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Training Data for Video Order" class="img-center" src="/images/ss-frame-order-data-gen.png"&gt;  &lt;/p&gt;
&lt;p&gt;To solve this pre-text task, &lt;a href="https://arxiv.org/pdf/1711.09082.pdf"&gt;Misra et al.&lt;/a&gt; propose an architecture where video frames are passed through weight-shared ConvNets and the model has to figure out whether the frames are in the correct order or not. In doing so, the model learns not just spatial features but also takes into account temporal features.
&lt;img alt="Architecture for Frame Order Verification" class="img-center" src="/images/ss-temporal-order-architecture.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1603.08561"&gt;Shuffle and Learn: Unsupervised Learning using Temporal Order&amp;nbsp;Verification&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="citation-info-bibtex"&gt;Citation Info&amp;nbsp;(BibTex)&lt;/h2&gt;
&lt;p&gt;If you found this blog post useful, please consider citing it&amp;nbsp;as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@misc{chaudhary2020selfsupervised,
  title   = {The Illustrated Self-Supervised Learning},
  author  = {Amit Chaudhary},
  year    = 2020,
  note    = {\url{https://amitness.com/2020/02/illustrated-self-supervised-learning}}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jing, et al. â&lt;a href="https://arxiv.org/abs/1902.06162"&gt;Self-Supervised Visual Feature Learning with Deep Neural Networks: A Survey.&lt;/a&gt;â&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Back Translation for Text Augmentation with GoogleÂ Sheets</title><link href="https://amitness.com/2020/02/back-translation-in-google-sheets/" rel="alternate"></link><published>2020-02-19T16:13:00+05:45</published><updated>2020-02-19T16:13:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2020-02-19:/2020/02/back-translation-in-google-sheets/</id><summary type="html">&lt;p&gt;Learn how to augment existing labeled text data for free using Google&amp;nbsp;Sheets.&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working on Natural Language Processing applications such as Text Classification, collecting enough labeled examples for each category manually can be difficult. In this article, I will go over an interesting technique to augment your existing text data automatically called back&amp;nbsp;translation.&lt;/p&gt;
&lt;h2 id="introduction-to-back-translation"&gt;Introduction to Back&amp;nbsp;Translation&lt;/h2&gt;
&lt;p&gt;The key idea of back translation is very simple. We create augmented version of a sentence using the following&amp;nbsp;steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You take the original text written in&amp;nbsp;English  &lt;/li&gt;
&lt;li&gt;You convert it into another language (say French) using Google&amp;nbsp;Translate  &lt;/li&gt;
&lt;li&gt;You convert the translated text back into English using Google&amp;nbsp;Translate   &lt;/li&gt;
&lt;li&gt;Keep the augmented text if the original text and the back-translated text are&amp;nbsp;different. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Backtranslation with English and French" class="img-center" src="/images/backtranslation-en-fr.png"&gt;
&lt;p class="has-text-centered has-text-grey"&gt;
Figure: Back&amp;nbsp;Translation
&lt;/p&gt;&lt;/p&gt;
&lt;h2 id="using-back-translation-in-google-sheets"&gt;Using Back Translation in Google&amp;nbsp;Sheets&lt;/h2&gt;
&lt;p&gt;We need a machine translation service to perform the translation to a different language and back to English. Google Translate is the most popular service for this purpose, but you need to get an &lt;span class="caps"&gt;API&lt;/span&gt; key to use it and it is a paid&amp;nbsp;service. &lt;/p&gt;
&lt;p&gt;Luckily, Google provides a handy feature in their Google Sheets web app, which we can leverage for our&amp;nbsp;purpose.&lt;/p&gt;
&lt;h3 id="step-1-load-your-data"&gt;Step 1: Load your&amp;nbsp;data&lt;/h3&gt;
&lt;p&gt;Let&amp;#8217;s assume we are building a sentiment analysis model and our dataset has sentences and their associated labels. We can load it into Google Sheets by importing the Excel/&lt;span class="caps"&gt;CSV&lt;/span&gt; file directly.
&lt;img alt="Loading Files in Google Sheets" src="/images/backtranslation-sheets-step-1.png"&gt;&lt;/p&gt;
&lt;h2 id="step-2-add-a-column-to-hold-augmented-data"&gt;Step 2: Add a column to hold augmented&amp;nbsp;data&lt;/h2&gt;
&lt;p&gt;Add a new column and use the &lt;code&gt;GOOGLETRANSLATE()&lt;/code&gt; function to translate from English to French and back to English.
&lt;img alt="Add column for translation" src="/images/backtranslation-sheets-step-2.png"&gt;&lt;/p&gt;
&lt;p&gt;The command to place in the column&amp;nbsp;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;GOOGLETRANSLATE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;GOOGLETRANSLATE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;A2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;fr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;fr&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once the command is placed, press Enter and you will see the translation.
&lt;img alt="Run translation on cells" src="/images/backtranslation-sheets-step-2.2.png"&gt;&lt;/p&gt;
&lt;p&gt;Now, select the first cell of &amp;#8220;Backtranslated&amp;#8221; column and drag the small square at the bottom right side below to apply this formula over the whole column 
&lt;img alt="Drag translation to all cells" src="/images/backtranslation-sheets-step-2.3.png"&gt;&lt;/p&gt;
&lt;p&gt;This should apply to all your training texts and you will get back the augmented version.
&lt;img alt="Example of translated rows" src="/images/backtranslation-sheets-step-2.4.png"&gt;&lt;/p&gt;
&lt;h2 id="step-3-filter-out-duplicated-data"&gt;Step 3: Filter out duplicated&amp;nbsp;data&lt;/h2&gt;
&lt;p&gt;For texts where the original text and what get back from &lt;code&gt;back translation&lt;/code&gt; are the same, we can filter them out programmatically by comparing the original text column and the augmented column. Then, only keep responses that have &lt;code&gt;True&lt;/code&gt; value in the &lt;code&gt;Changed&lt;/code&gt; column.
&lt;img alt="Filter out same translation" src="/images/backtranslation-sheets-step-3.2.png"&gt;&lt;/p&gt;
&lt;h2 id="step-4-export-your-data"&gt;Step 4: Export your&amp;nbsp;data&lt;/h2&gt;
&lt;p&gt;You can download your data as a &lt;span class="caps"&gt;CSV&lt;/span&gt; file and augment your existing training&amp;nbsp;data.&lt;/p&gt;
&lt;h2 id="example-sheet"&gt;Example&amp;nbsp;Sheet&lt;/h2&gt;
&lt;p&gt;Here is a &lt;a href="https://docs.google.com/spreadsheets/d/1pE9RAukrc4S9jf22RxVr_vEBqN9_DyZaRY8QQRek8Fs/edit#gid=2000059744"&gt;Google Sheet&lt;/a&gt; demonstrating all the four steps above. You can refer to that and make a copy of it to test things&amp;nbsp;out.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Back translation offers an interesting approach when you&amp;#8217;ve small training data but want to improve the performance of your&amp;nbsp;model.&lt;/p&gt;</content></entry><entry><title>Visual Paper Summary: ALBERT (A Lite BERT)</title><link href="https://amitness.com/2020/02/albert-visual-summary/" rel="alternate"></link><published>2020-02-08T22:00:00+05:45</published><updated>2020-02-08T22:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2020-02-08:/2020/02/albert-visual-summary/</id><summary type="html">&lt;p&gt;An illustrated summary of &lt;span class="caps"&gt;ALBERT&lt;/span&gt;&amp;nbsp;paper.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Consider a sentence given below. As humans, when we encounter the word &amp;#8220;&lt;strong&gt;apple&lt;/strong&gt;&amp;#8220;, we&amp;nbsp;could: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Associate the word &amp;#8220;apple&amp;#8221; to our mental representation of the fruit&amp;nbsp;&amp;#8220;apple&amp;#8221;  &lt;/li&gt;
&lt;li&gt;Associate &amp;#8220;apple&amp;#8221; to the fruit rather than the company based on the&amp;nbsp;context  &lt;/li&gt;
&lt;li&gt;Understand the big picture that &amp;#8220;&lt;em&gt;he ate an apple&lt;/em&gt;&amp;#8221;  &lt;/li&gt;
&lt;li&gt;Understand it at character-level, word-level and&amp;nbsp;sentence-level  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Representations in Humans vs Machines" class="img-center" src="/images/nlp-representation-learning.png"&gt;    &lt;/p&gt;
&lt;p&gt;The basic premise of latest developments in &lt;span class="caps"&gt;NLP&lt;/span&gt; is to give machines the ability to learn such&amp;nbsp;representations. &lt;/p&gt;
&lt;p&gt;In 2018, Google released &lt;span class="caps"&gt;BERT&lt;/span&gt; that attempted to learn representations based on a few novel&amp;nbsp;ideas:&lt;/p&gt;
&lt;h2 id="recap-bert"&gt;Recap:  &lt;span class="caps"&gt;BERT&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id="1-masked-language-modeling"&gt;1. Masked Language&amp;nbsp;Modeling&lt;/h3&gt;
&lt;p&gt;Language modeling basically involves predicting the word given its context as a way to learn representation. Tradionally, this involved predicting the next word in sentence given previous words.
&lt;img alt="Language Modeling in NLP" class="img-center" src="/images/nlp-language-model-1.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;BERT&lt;/span&gt; instead used a &lt;strong&gt;masked language model&lt;/strong&gt; objective, in which we randomly mask words in document and try to predict them based on surrounding context.
&lt;img alt="Masked Language Model in BERT" class="img-center" src="/images/bert-masked-language-model.png"&gt;&lt;br&gt;
&lt;p class="has-text-centered"&gt;
Credits: &lt;a href="https://giphy.com/stickers/marvelstudios-oh-thanos-snapped-TfjfIgE9YUgdyz8V1J"&gt;Marvel Studios on&amp;nbsp;Giphy&lt;/a&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;h3 id="2-next-sentence-prediction"&gt;2. Next Sentence&amp;nbsp;Prediction&lt;/h3&gt;
&lt;p&gt;The idea with &amp;#8220;Next Sentence Prediction&amp;#8221; is to detect whether two sentences are coherent when placed one after another or not.
&lt;img alt="Next Sentence Prediction Task" class="img-center" src="/images/bert-nsp.png"&gt;  &lt;/p&gt;
&lt;p&gt;For this, consecutive sentences from the training data are used as a positive example. For negative example, some sentence is taken and a random sentence from another document is placed next to it. &lt;span class="caps"&gt;BERT&lt;/span&gt; model is trained on this task to identify if two sentences can occur next to each&amp;nbsp;other.&lt;/p&gt;
&lt;h3 id="3-transformer-architecture"&gt;3. Transformer&amp;nbsp;Architecture&lt;/h3&gt;
&lt;p&gt;To solve the above two tasks, &lt;span class="caps"&gt;BERT&lt;/span&gt; uses stacked layers of transformer blocks as encoders. Word vectors are passed through the layers to capture the meaning and yeild a vector of size 768 for the base&amp;nbsp;model.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Transformer Layers in BERT" src="/images/bert-blocks.png"&gt;
Jay Alammar has an &lt;a href="http://jalammar.github.io/illustrated-bert/"&gt;excellent post&lt;/a&gt; that illustrates the internals of transformers in more&amp;nbsp;depth.&lt;/p&gt;
&lt;h2 id="problems-with-bert"&gt;Problems with &lt;span class="caps"&gt;BERT&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;BERT&lt;/span&gt;, when released, yielded state of art results on many &lt;span class="caps"&gt;NLP&lt;/span&gt; tasks on leaderboards. But, the model was very large in size which resulted in some issues. The &amp;#8220;&lt;span class="caps"&gt;ALBERT&lt;/span&gt;&amp;#8221; paper highlights these issues in two&amp;nbsp;categories:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Memory Limitation and Communication Overhead:&lt;/strong&gt;&lt;br&gt;
    Consider a simple neural network with one input node, two hidden nodes and a output node. Even such a simple neural network will have 7 parameters to learn due to weights and bias per node.&lt;br&gt;
&lt;img alt="Number of parameters in a neural network" class="img-center" src="/images/small-network-parameters.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;BERT&lt;/span&gt;-large, being a complex model, has 340 million parameters because of to its 24 hidden layers and lots of nodes in feed-forward network and attention heads. If you wanted to build upon the work on &lt;span class="caps"&gt;BERT&lt;/span&gt; and brings improvements to it, you would require large compute requirements to train from scratch and iterate on it.
&lt;img alt="BERT overload on GPU" class="img-center" src="/images/bert-heavy-on-gpu.png"&gt;&lt;br&gt;
These compute requirements mainly involve GPUs and TPUs, but such devices have a memory limitation. So, there is a limit to the size of&amp;nbsp;models.&lt;/p&gt;
&lt;p&gt;One popular approach to this problem in distributed training. Let&amp;#8217;s take example of data parallelism on &lt;span class="caps"&gt;BERT&lt;/span&gt;-large, where training data is divided into two machines. The model is trained on two machines on chunks of data. As shown in the figure, you can notice how the large number of parameters to transfer during synchronization of gradients can slow down the training process. The same bottleneck applies for the model parallelism as well where we store different parts of the model(parameters) on different machines.
&lt;img alt="Communication Overhead in Distributed Training" class="img-center" src="/images/bert-communication-overhead.png"&gt; 
&lt;p class="has-text-centered"&gt;
    Figure: Communication overhead in distributed&amp;nbsp;training
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Degradation&lt;/strong&gt;&lt;br&gt;
    Recent trend in the &lt;span class="caps"&gt;NLP&lt;/span&gt; research community is using larger and larger models to get state-of-the-art performance on leaderboards. &lt;span class="caps"&gt;ALBERT&lt;/span&gt; shows that that this can have diminishing&amp;nbsp;returns.  &lt;/p&gt;
&lt;p&gt;In the paper, the authors performed an interesting&amp;nbsp;experiment. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If larger models lead to better performance, why not double the hidden layer units of the largest available &lt;span class="caps"&gt;BERT&lt;/span&gt; model(&lt;span class="caps"&gt;BERT&lt;/span&gt;-large) from 1024 units to 2048&amp;nbsp;units? &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;They call it &amp;#8220;&lt;span class="caps"&gt;BERT&lt;/span&gt;-xlarge&amp;#8221;. Surprisingly, the larger model actually performs worse than the &lt;span class="caps"&gt;BERT&lt;/span&gt;-large model on both Language Modeling task as well as when tested on a reading comprehension test (&lt;span class="caps"&gt;RACE&lt;/span&gt;).
&lt;img alt="BERT-xlarge vs BERT-large on RACE benchmark" src="/images/bert-doubled-performance-race.png"&gt;&lt;/p&gt;
&lt;p&gt;From the plots given in the original paper, we can see how the performance degrades. &lt;span class="caps"&gt;BERT&lt;/span&gt;-xlarge is performing worse than &lt;span class="caps"&gt;BERT&lt;/span&gt;-large even though it is larger in size and has more parameters.
&lt;img alt="Performance graph for BERT x-large vs large" src="/images/bert-xlarge-vs-bert-large.png"&gt;
&lt;p class="has-text-centered"&gt;
    Credits: &lt;span class="caps"&gt;ALBERT&lt;/span&gt;&amp;nbsp;paper
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="from-bert-to-albert"&gt;From &lt;span class="caps"&gt;BERT&lt;/span&gt; to &lt;span class="caps"&gt;ALBERT&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;ALBERT&lt;/span&gt; attacks these problems by building upon on &lt;span class="caps"&gt;BERT&lt;/span&gt; with a few novel&amp;nbsp;ideas:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cross-layer parameter sharing&lt;/strong&gt;&lt;br&gt;
    &lt;span class="caps"&gt;BERT&lt;/span&gt; large model had 24 layers while it&amp;#8217;s base version had 12-layers. As we add more layers, we increase the number of parameters exponentially.&lt;br&gt;
&lt;img alt="Exponential increase in parameters for BERT" src="/images/bert-parameters.png"&gt;&lt;/p&gt;
&lt;p&gt;To solve this problem, &lt;span class="caps"&gt;ALBERT&lt;/span&gt; uses the concept of cross-layer parameter sharing. To illustrate, let&amp;#8217;s see the example of 12-layer &lt;span class="caps"&gt;BERT&lt;/span&gt;-base model. Instead of learning unique parameters for each of the 12 layers, we only learn parameters for the first block, and reuse the block in the remaining 11&amp;nbsp;layers.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Parameter sharing in ALBERT" src="/images/albert-parameter-sharing.png"&gt;&lt;/p&gt;
&lt;p&gt;We can share parameter for either feed-forward layer only, the attention parameters only or share the parameters of the whole block itself. The paper shares the parameters for whole&amp;nbsp;block.&lt;/p&gt;
&lt;p&gt;Compared to the 110 million paramters of &lt;span class="caps"&gt;BERT&lt;/span&gt;-base, the &lt;span class="caps"&gt;ALBERT&lt;/span&gt; model only has 31 million parameters while using the same number of layers and 768 hidden units. The effect on accuracy is minimal for embedding size of 128. Major drop in accuracy is due to feed-forward network parameter sharing. Effect of sharing attention parameters is minimal.
&lt;img alt="Reduction in parameters due to weight-sharing" src="/images/albert-parameter-sharing-results.png"&gt;
&lt;p class="has-text-centered"&gt;
    Figure: Effect of cross-layer parameter strategy on&amp;nbsp;performance
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sentence-Order Prediction (&lt;span class="caps"&gt;SOP&lt;/span&gt;)&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;BERT&lt;/span&gt; introduced a binary classification loss called &amp;#8220;&lt;strong&gt;Next Sentence Prediction&lt;/strong&gt;&amp;#8220;. This was specifically created to improve performance on downstream tasks that use sentence pairs like &amp;#8220;Natural Language Inference&amp;#8221;. The basic process&amp;nbsp;is:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take two segments that appear consecutively from training&amp;nbsp;corpus  &lt;/li&gt;
&lt;li&gt;Create a random pair of segment from different document as negative examples
&lt;img alt="Next Sentence Prediction Data Format" src="/images/nsp-training-data-generation.png"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Papers like &lt;a href="https://arxiv.org/abs/1907.11692"&gt;&lt;span class="caps"&gt;ROBERTA&lt;/span&gt;&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/1906.08237"&gt;&lt;span class="caps"&gt;XLNET&lt;/span&gt;&lt;/a&gt; have shed light on the ineffectiveness of &lt;span class="caps"&gt;NSP&lt;/span&gt; and found it&amp;#8217;s impact on the downstream tasks unreliable. On eliminating the &lt;span class="caps"&gt;NSP&lt;/span&gt; task, the performance across several tasks&amp;nbsp;improved.&lt;/p&gt;
&lt;p&gt;So, &lt;span class="caps"&gt;ALBERT&lt;/span&gt; proposes an alternative task called &lt;strong&gt;&amp;#8220;Sentence Order Prediction&amp;#8221;&lt;/strong&gt;. The key idea&amp;nbsp;is:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take two consecutive segments from same document as positive&amp;nbsp;class  &lt;/li&gt;
&lt;li&gt;Swap the order of the same segment and use that as negative example&lt;br&gt;
&lt;img alt="Sentence Order Prediction" src="/images/sentence-order-prediction.png"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The forces the model to learn finer-grained distinction about discourse-level coherence&amp;nbsp;properties.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;ALBERT&lt;/span&gt; conjectures that &lt;span class="caps"&gt;NSP&lt;/span&gt; was ineffective because it&amp;#8217;s not a difficult task when compared to masked language modeling. In a single task, it mixes both topic prediction and coherence prediction. The topic prediction part is easy to learn because it overlaps with the masked language model loss. Thus, &lt;span class="caps"&gt;NSP&lt;/span&gt; will give higher scores even when it hasn&amp;#8217;t learned coherence&amp;nbsp;prediction.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;SOP&lt;/span&gt; improves performance on downstream multi-sentence encoding tasks (&lt;span class="caps"&gt;SQUAD&lt;/span&gt; 1.1, 2.0, &lt;span class="caps"&gt;MNLI&lt;/span&gt;, &lt;span class="caps"&gt;SST&lt;/span&gt;-2, &lt;span class="caps"&gt;RACE&lt;/span&gt;).
&lt;img alt="Sentence Order Prediction Impact" src="/images/sop-results-albert.png"&gt;&lt;/p&gt;
&lt;p&gt;Here we can see how model trained on &lt;span class="caps"&gt;NSP&lt;/span&gt; is only giving scores slightly better than random baseline on &lt;span class="caps"&gt;SOP&lt;/span&gt; task, but model trained on &lt;span class="caps"&gt;SOP&lt;/span&gt; can solve the &lt;span class="caps"&gt;NSP&lt;/span&gt; task quite effectively. This provides evidence that &lt;span class="caps"&gt;SOP&lt;/span&gt; leads to better learning&amp;nbsp;representation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Factorized embedding parameterization&lt;/strong&gt; &lt;br&gt;
    In &lt;span class="caps"&gt;BERT&lt;/span&gt;, the embeddings used (word piece embeddings) size was linked to the hidden layer sizes of the transformer blocks. Word piece embeddings learnt from the one hot encoding representations of a vocabulary of size 30,000 was used. These are projected directly to the hidden space of the hidden&amp;nbsp;layer.  &lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s say we have a vocabulary of size 30K, word-piece embedding of dimension E=768 and hidden layer of size H=768. If we increase hidden units in the block, then we need to add a new dimension to each embedding as well. This problem is prevalent in &lt;span class="caps"&gt;XLNET&lt;/span&gt; and &lt;span class="caps"&gt;ROBERTA&lt;/span&gt; as well.
&lt;img alt="Factorized Embedding Parameterization" class="img-center" src="/images/bert-embedding.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;ALBERT&lt;/span&gt; solves this problem by factorizing the large vocabulary embedding matrix into two smaller matrices. This separates the size of the hidden layers from the size of the vocabulary embeddings. This allows us to grow the hidden size without significantly increasing the parameter size of the vocabulary embeddings.
&lt;img alt="Decomposing Embeddings into factors" class="img-center" src="/images/embedding-decompose-albert.png"&gt;&lt;/p&gt;
&lt;p&gt;We project the One Hot Encoding vector into the lower dimension embedding space of E=100 and then this embedding space into the hidden space&amp;nbsp;H=768.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="results"&gt;Results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;18x fewer parameters than &lt;span class="caps"&gt;BERT&lt;/span&gt;-large&lt;/li&gt;
&lt;li&gt;Trained 1.7x&amp;nbsp;faster&lt;/li&gt;
&lt;li&gt;Got &lt;span class="caps"&gt;SOTA&lt;/span&gt; results on &lt;span class="caps"&gt;GLUE&lt;/span&gt;, &lt;span class="caps"&gt;RACE&lt;/span&gt; and &lt;span class="caps"&gt;SQUAD&lt;/span&gt; during its release&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;RACE&lt;/span&gt;: 89.4% [45.3%&amp;nbsp;improvement]&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;GLUE&lt;/span&gt; Benchmark:&amp;nbsp;89.4&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;SQUAD&lt;/span&gt; 2.0 F1-score:&amp;nbsp;92.2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;ALBERT&lt;/span&gt; marks an important step towards building language models that not only get &lt;span class="caps"&gt;SOTA&lt;/span&gt; on the leaderboards but are also feasible for real-world&amp;nbsp;applications.&lt;/p&gt;
&lt;h2 id="citation-info-bibtex"&gt;Citation Info&amp;nbsp;(BibTex)&lt;/h2&gt;
&lt;p&gt;If you found this blog post useful, please consider citing it&amp;nbsp;as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@misc{chaudhary2020albert,
  title   = {Visual Paper Summary: ALBERT (A Lite BERT)},
  author  = {Amit Chaudhary},
  year    = 2020,
  note    = {\url{https://amitness.com/2020/02/albert-visual-summary}}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1909.11942.pdf"&gt;&lt;span class="caps"&gt;ALBERT&lt;/span&gt;: A Lite &lt;span class="caps"&gt;BERT&lt;/span&gt; for Self-supervised Learning of Language&amp;nbsp;Representations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Transfer Learning in NLP with Tensorflow Hub andÂ Keras</title><link href="https://amitness.com/2020/02/tensorflow-hub-for-transfer-learning/" rel="alternate"></link><published>2020-02-02T19:00:00+05:45</published><updated>2020-02-02T19:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2020-02-02:/2020/02/tensorflow-hub-for-transfer-learning/</id><summary type="html">&lt;p&gt;Learn how to integrate and finetune tensorflow-hub modules in Tensorflow&amp;nbsp;2.0&lt;/p&gt;</summary><content type="html">&lt;p&gt;Tensorflow 2.0 introduced Keras as the default high-level &lt;span class="caps"&gt;API&lt;/span&gt; to build models. Combined with pretrained models from Tensorflow Hub, it provides a dead-simple way for transfer learning in &lt;span class="caps"&gt;NLP&lt;/span&gt; to create good models out of the&amp;nbsp;box.   &lt;/p&gt;
&lt;p&gt;&lt;img alt="Clickbait Title Illustration" src="/images/clickbait-or-not-illustration.png"&gt;&lt;br&gt;
To illustrate the process, let&amp;#8217;s take an example of classifying if the title of an article is clickbait or&amp;nbsp;not.&lt;/p&gt;
&lt;h2 id="data-preparation"&gt;Data&amp;nbsp;Preparation&lt;/h2&gt;
&lt;p&gt;We will use the dataset from the paper &lt;a href="https://people.mpi-sws.org/~achakrab/papers/chakraborty_clickbait_asonam16.pdf"&gt;&amp;#8216;Stop Clickbait: Detecting and Preventing Clickbaits in Online News Media&amp;#8217;&lt;/a&gt; available &lt;a href="https://github.com/bhargaviparanjape/clickbait"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since the goal of this article is to illustrate transfer learning, we will directly load an already pre-processed dataset into a pandas&amp;nbsp;dataframe.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;http://bit.ly/clickbait-data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The dataset consists of page titles and labels. The label is 1 if the title is clickbait.
&lt;img alt="Rows of training data for clickbait detection" src="/images/clickbait-pandas-dataframe.png"&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s split the data into 70% training data and 30% validation&amp;nbsp;data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;

&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                                                    &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;label&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                                                    &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                    &lt;span class="n"&gt;stratify&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;label&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                                                    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="model-architecture"&gt;Model&amp;nbsp;Architecture&lt;/h2&gt;
&lt;p&gt;Now, we install tensorflow and tensorflow-hub using&amp;nbsp;pip.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install tensorflow-hub
pip install &lt;span class="nv"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.1.0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To use text data as features for models, we need to convert it into a numeric form. Tensorflow Hub provides various &lt;a href="https://tfhub.dev/s?module-type=text-embedding&amp;amp;q=tf2"&gt;modules&lt;/a&gt; for converting the sentences into embeddings such as &lt;span class="caps"&gt;BERT&lt;/span&gt;, &lt;span class="caps"&gt;NNLM&lt;/span&gt; and&amp;nbsp;Wikiwords.&lt;/p&gt;
&lt;p&gt;Universal Sentence Encoder is one of the popular module for generating sentence embeddings. It gives back a 512 fixed-size vector for the text.
Below is an example of how we can use tensorflow hub to capture embeddings for the sentence &amp;#8220;Hello&amp;nbsp;World&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Universal Sentence Encoder applied on Hello World" src="/images/use-on-hello-world.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow_hub&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;hub&lt;/span&gt;

&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://tfhub.dev/google/universal-sentence-encoder/4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Hello World&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Universal Sentence Encodings Output" src="/images/use-output.png"&gt;&lt;/p&gt;
&lt;p&gt;In Tensorflow 2.0, using these embeddings in our models is a piece of cake thanks to the new &lt;a href="https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer"&gt;hub.KerasLayer&lt;/a&gt; module. Let&amp;#8217;s design a tf.keras model for the binary classification task of clickbait&amp;nbsp;detection.&lt;/p&gt;
&lt;p&gt;First import the required&amp;nbsp;libraries.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow_hub&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;hub&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then, we create a sequential model that will encapsulate our&amp;nbsp;layers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first layer will be a hub.KerasLayer from where we can loading models available at &lt;a href="https://tfhub.dev/"&gt;tfhub.dev&lt;/a&gt;. We will be loading &lt;a href="https://tfhub.dev/google/universal-sentence-encoder/4"&gt;Universal Sentence Encoder&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;KerasLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://tfhub.dev/google/universal-sentence-encoder/4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[],&lt;/span&gt; 
                        &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;trainable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here are what the different parameters used&amp;nbsp;mean:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/4&lt;/code&gt;: It denotes the variant of Universal Sentence Encoder on hub. We&amp;#8217;re using the &lt;code&gt;Deep Averaging Network (DAN)&lt;/code&gt; variant. We also have &lt;a href="https://tfhub.dev/google/universal-sentence-encoder-large/5"&gt;Transformer architecture&lt;/a&gt; and other &lt;a href="https://tfhub.dev/google/collections/universal-sentence-encoder/1"&gt;variants&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;input_shape=[]&lt;/code&gt;: Since our data has no features but the text itself, so there feature dimension is&amp;nbsp;empty. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;dtype=tf.string&lt;/code&gt;: Since we&amp;#8217;ll be passing raw text itself to the&amp;nbsp;model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;trainable=True&lt;/code&gt;: Denotes whether we want to finetune &lt;span class="caps"&gt;USE&lt;/span&gt; or not. We set it to True, the embeddings present in &lt;span class="caps"&gt;USE&lt;/span&gt; are finetuned based on our downstream&amp;nbsp;task.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next, we add a Dense layer with single node to output probability of clickbait between 0 and&amp;nbsp;1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In summary, we have a model that takes text data, projects it into 512-dimension embedding and passed that through a feedforward neural network with sigmoid activation to give a clickbait&amp;nbsp;probability.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Keras Model Architecture for Clickbait Detection" src="/images/clickbait-keras-model.png"&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we can implement the exact above architecture using the tf.keras functional &lt;span class="caps"&gt;API&lt;/span&gt; as&amp;nbsp;well.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;KerasLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://tfhub.dev/google/universal-sentence-encoder/4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                    &lt;span class="n"&gt;trainable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output of the model summary&amp;nbsp;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Model summary from Keras model" src="/images/clickbait-model-summary.png"&gt;&lt;/p&gt;
&lt;p&gt;The number of trainable parameters is &lt;code&gt;256,798,337&lt;/code&gt; because we&amp;#8217;re finetuning Universal Sentence&amp;nbsp;Encoder.&lt;/p&gt;
&lt;h2 id="training-the-model"&gt;Training the&amp;nbsp;model&lt;/h2&gt;
&lt;p&gt;Since we&amp;#8217;re performing a binary classification task, we use a binary cross entropy loss along with &lt;span class="caps"&gt;ADAM&lt;/span&gt; optimizer and accuracy as the&amp;nbsp;metric.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, let&amp;#8217;s train the model&amp;nbsp;for &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
          &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
          &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
          &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We reach a training accuracy of 99.62% and validation accuracy of 98.46% with only 2&amp;nbsp;epochs.  &lt;/p&gt;
&lt;h2 id="inference"&gt;Inference&lt;/h2&gt;
&lt;p&gt;Let&amp;#8217;s test the model on a few&amp;nbsp;examples.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Clickbait&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;21 Pictures That Will Make You Feel Like You&amp;#39;re 99 Years Old&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.9997924&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Not Clickbait&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Google announces TensorFlow 2.0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;0.00022611&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Thus, with a combination of Tensorflow Hub and tf.keras, we can leverage transfer learning easily and build high-performance models for any of our downstream&amp;nbsp;tasks.&lt;/p&gt;
&lt;h2 id="data-credits"&gt;Data&amp;nbsp;Credits&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Abhijnan Chakraborty, Bhargavi Paranjape, Sourya Kakarla, and Niloy Ganguly. "Stop Clickbait: Detecting and Preventing Clickbaits in Online News Mediaâ. In Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), San Fransisco, US, August 2016&lt;/code&gt;&lt;/p&gt;</content></entry><entry><title>Migrating from OS.PATH to PATHLIB Module inÂ Python</title><link href="https://amitness.com/2019/12/migrating-to-pathlib/" rel="alternate"></link><published>2019-12-29T23:28:00+05:45</published><updated>2019-12-29T23:28:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2019-12-29:/2019/12/migrating-to-pathlib/</id><summary type="html">&lt;p&gt;Learn how to use the modern pathlib module to perform tasks you have been using os.path&amp;nbsp;for.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this article, I will go over the most frequent tasks related to file paths and show how you can refactor the old approach of using &lt;a href="https://docs.python.org/3/library/os.path.html"&gt;os.path&lt;/a&gt; module to the new cleaner way using &lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;pathlib&lt;/a&gt;&amp;nbsp;module.&lt;/p&gt;
&lt;h2 id="joining-paths"&gt;Joining&amp;nbsp;paths&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;base_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In pathlib, we can use the division operator to separate the paths&amp;nbsp;elegantly.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;base_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-absolute-path"&gt;Get absolute&amp;nbsp;path&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abspath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__file__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__file__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resolve&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-current-working-directory"&gt;Get current working&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cwd&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="check-if-path-is-a-file"&gt;Check if path is a&amp;nbsp;file&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_file&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="check-if-path-is-a-directory"&gt;Check if path is a&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_dir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="check-if-a-path-exists"&gt;Check if a path&amp;nbsp;exists&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-path-to-folder-containing-a-file"&gt;Get path to folder containing a&amp;nbsp;file&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dirname&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# /home/ubuntu&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parent&lt;/span&gt;
&lt;span class="c1"&gt;# /home/ubuntu&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-the-path-to-the-home-directory"&gt;Get the path to the home&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="expand-the-user-home-directory-in-a-path"&gt;Expand the user home directory in a&amp;nbsp;path&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~/Desktop&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;#39;/home/ubuntu/Desktop&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~/Desktop&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-size-in-bytes-of-a-file"&gt;Get size in bytes of a&amp;nbsp;file&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getsize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-file-extension"&gt;Get file&amp;nbsp;extension&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/hello.py&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# (&amp;#39;/home/ubuntu/hello&amp;#39;, &amp;#39;.py&amp;#39;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/hello.py&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;suffix&lt;/span&gt;
&lt;span class="c1"&gt;# .py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="change-permission-of-a-file"&gt;Change permission of a&amp;nbsp;file&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chmod&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;key.pem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;o400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;key.pem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chmod&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;o400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="get-file-name-without-directory"&gt;Get file name without&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/hello.py&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# hello.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/hello.py&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="c1"&gt;# hello.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="list-contents-of-a-directory"&gt;List contents of a&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="create-a-directory"&gt;Create a&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makedirs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exist_ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;exist_ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="rename-files-or-directories"&gt;Rename files or&amp;nbsp;directories&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;rows.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;rows.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="delete-a-directory"&gt;Delete a&amp;nbsp;directory&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rmdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rmdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="reading-a-file"&gt;Reading a&amp;nbsp;file&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In new versions of python, you can directly pass a pathlib &lt;code&gt;Path&lt;/code&gt; to the &lt;code&gt;open()&lt;/code&gt; function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In older versions, you can either convert the path to a string using &lt;code&gt;str()&lt;/code&gt; or use the &lt;code&gt;open()&lt;/code&gt; method.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Method: 1&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Method 2&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Method 3&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content></entry><entry><title>Math Symbols Explained withÂ Python</title><link href="https://amitness.com/2019/08/math-for-programmers/" rel="alternate"></link><published>2019-08-03T06:53:00+05:45</published><updated>2019-08-03T06:53:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2019-08-03:/2019/08/math-for-programmers/</id><summary type="html">&lt;p&gt;Learn the meaning behind mathematical symbols used in Machine Learning using your knowledge of&amp;nbsp;Python.&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working with Machine Learning projects, you will come across a wide variety of equations that you need to implement in code. Mathematical notations capture a concept so eloquently but unfamiliarity with them makes them&amp;nbsp;obscure.&lt;/p&gt;
&lt;p&gt;In this post, I&amp;#8217;ll be explaining the most common math notations by connecting it with its analogous concept in Python. Once you learn them, you will be able to intuitively grasp the intention of an equation and be able to implement it in code.
&lt;pre class="math"&gt;
\frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y_i})^2
&lt;/pre&gt;&lt;/p&gt;
&lt;h2 id="indexing"&gt;Indexing&lt;/h2&gt;
&lt;p&gt;&lt;pre class="math"&gt;
x_i
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This symbol is taking the value at i&lt;tt class="math"&gt;^{th}&lt;/tt&gt; index of a&amp;nbsp;vector.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# 10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This can be extended for 2D vectors and so on.
&lt;pre class="math"&gt;
x_{ij}
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# 20&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="sigma"&gt;Sigma&lt;/h2&gt;
&lt;pre class="math"&gt;
\sum_{i=1}^{N} x_i
&lt;/pre&gt;

&lt;p&gt;This symbol finds the sum of all elements in a vector for a given range. Both lower and upper limits are inclusive. In Python, it is equivalent to looping over a vector from index 0 to index N-1. Notice how we&amp;#8217;re using the previously explained &lt;tt class="math"&gt;x_i&lt;/tt&gt; symbol to get the value at&amp;nbsp;index.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
 &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above code can even be shortened using built-in functions in Python&amp;nbsp;as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="average"&gt;Average&lt;/h2&gt;
&lt;pre class="math"&gt;
\frac{1}{N}\sum_{i=1}^{N} x_i
&lt;/pre&gt;

&lt;p&gt;Here we reuse the sigma notation and divide by the number of elements to get an&amp;nbsp;average.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
 &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;average&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above code can even be shortened in Python&amp;nbsp;as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="pi"&gt;&lt;span class="caps"&gt;PI&lt;/span&gt;&lt;/h2&gt;
&lt;pre class="math"&gt;
\prod_{i=1}^{N} x_i
&lt;/pre&gt;

&lt;p&gt;This symbol finds the product of all elements in a vector for a given range. In Python, it is equivalent to looping over a vector from index 0 to index N-1 and multiplying&amp;nbsp;them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
 &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="pipe"&gt;Pipe&lt;/h2&gt;
&lt;p&gt;The pipe symbol can mean different things based on where it&amp;#8217;s&amp;nbsp;applied.&lt;/p&gt;
&lt;h3 id="absolute-value"&gt;Absolute&amp;nbsp;Value&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
| x | 
&lt;/pre&gt;
&lt;pre class="math"&gt;
| y | 
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This symbol denotes the absolute value of a number i.e. without a&amp;nbsp;sign.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 10&lt;/span&gt;
&lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 20&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="norm-of-vector"&gt;Norm of&amp;nbsp;vector&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
| x |
&lt;/pre&gt;
&lt;pre class="math"&gt;
|| x || 
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;The norm is used to calculate the magnitude of a vector. In Python, this means squaring each element of an array, summing them and then taking the square&amp;nbsp;root.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="epsilon"&gt;Epsilon&lt;/h2&gt;
&lt;p&gt;&lt;pre class="math"&gt;
3\ \epsilon\ X
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This symbol checks if an element is part of a set. In Python, this would be equivalent&amp;nbsp;to&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="function"&gt;Function&lt;/h2&gt;
&lt;p&gt;&lt;pre class="math"&gt;
f: X \rightarrow Y
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This denotes a function which takes a domain X and maps it to range Y. In Python, it&amp;#8217;s equivalent to taking a pool of values X, doing some operation on it to calculate pool of values&amp;nbsp;Y.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
 &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
 &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You will encounter the following symbols in place of X and Y. Here are what they mean:
&lt;pre class="math"&gt;
f: R \rightarrow R
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; means input and outputs are real numbers and can take any value (integer, float, irrational, rational).
In Python, this is equivalent to any value except complex&amp;nbsp;numbers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;2.5&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You will also enounter symbols such as 
&lt;pre class="math"&gt;
f: R^d \rightarrow R
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;tt class="math"&gt;R^d&lt;/tt&gt; means d-dimensional vector of real&amp;nbsp;numbers.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s assume d = 2. In Python, an example can be a function that takes 2-D array and returns it&amp;#8217;s sum. It will be mapping a &lt;tt class="math"&gt;R^d&lt;/tt&gt; to &lt;tt class="math"&gt;R&lt;/tt&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;
&lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="tensors"&gt;Tensors&lt;/h2&gt;
&lt;h3 id="transpose"&gt;Transpose&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
X^T
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This is basically exchanging the rows and columns.
In Python, this would be equivalent&amp;nbsp;to&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Output would be a list with exchanged rows and&amp;nbsp;columns.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[[1, 4], 
 [2, 5],
 [3, 6]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="element-wise-multiplication"&gt;Element wise&amp;nbsp;multiplication&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
z = x \odot y
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;It means multiplying the corresponding elements in two tensors. In Python, this would be equivalent to multiplying the corresponding elements in two&amp;nbsp;lists.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multiply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Output&amp;nbsp;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[[2, 4]],
[[6, 8]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="dot-product"&gt;Dot&amp;nbsp;Product&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
XY \newline
X.Y
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;It gives the sum of the products of the corresponding entries of the two sequences of&amp;nbsp;numbers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# 1*4 + 2*5 + 3*7&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="hat"&gt;Hat&lt;/h3&gt;
&lt;p&gt;&lt;pre class="math"&gt;
\hat{x}
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;The hat gives the unit vector. This means dividing each component in a vector by it&amp;#8217;s&amp;nbsp;length(norm).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;x_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This makes the magnitude of the vector 1 and only keeps the&amp;nbsp;direction.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x_hat&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="c1"&gt;# 1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="exclamation"&gt;Exclamation&lt;/h2&gt;
&lt;p&gt;&lt;pre class="math"&gt;
x!
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;This denotes the factorial of a number. It is the product of numbers starting from 1 to that number. In Python, it can be calculated&amp;nbsp;as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;fact&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;fact&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fact&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fact&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The same thing can also be calculated using built-in&amp;nbsp;function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output&amp;nbsp;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 5*4*3*2*1
120
&lt;/pre&gt;&lt;/div&gt;</content></entry><entry><title>Identify the Language of Text usingÂ Python</title><link href="https://amitness.com/2019/07/identify-text-language-python/" rel="alternate"></link><published>2019-07-15T10:44:00+05:45</published><updated>2019-08-03T12:44:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2019-07-15:/2019/07/identify-text-language-python/</id><summary type="html">&lt;p&gt;Learn how to predict the language of a given piece of text using Natural Language&amp;nbsp;Processing.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Text Language Identification is the process of predicting the language of a given a piece of text. You might have encountered it when Chrome shows a popup to translate a webpage when it detects that the content is not in English. Behind the scenes, Chrome is using a model to predict the language of text used on a&amp;nbsp;webpage.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Google Translate Popup on Chrome" src="/images/google_translate_popup.png"&gt;&lt;/p&gt;
&lt;p&gt;When working with a dataset for &lt;span class="caps"&gt;NLP&lt;/span&gt;,  the corpus may contain a mixed set of languages. Here, language identification can be useful to either filter out a few languages or to translate the corpus to a single language and then use for your downstream&amp;nbsp;tasks.&lt;/p&gt;
&lt;p&gt;In this post, I will demonstrate how to use the Fasttext library for language&amp;nbsp;identification.&lt;/p&gt;
&lt;h2 id="facebooks-fasttext-library"&gt;Facebook&amp;#8217;s Fasttext&amp;nbsp;library&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Fasttext Logo" src="/images/fastText_logo.png"&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href="https://fasttext.cc/"&gt;Fasttext&lt;/a&gt; is an open-source library in Python for word embeddings and text classification. It is built for production use rather than research and hence is optimized for performance and size. It extends the &lt;a href="https://en.wikipedia.org/wiki/Word2vec"&gt;Word2Vec&lt;/a&gt; model with ideas such as using &lt;a href="https://arxiv.org/abs/1607.04606"&gt;subword information&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/1612.03651"&gt;model compression&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For our purpose of language identification, we can use the pre-trained models provided by fastText. The model was trained on a dataset drawn from &lt;a href="https://www.wikipedia.org/"&gt;Wikipedia&lt;/a&gt;, &lt;a href="https://tatoeba.org/eng/"&gt;Tatoeba&lt;/a&gt;, and &lt;a href="http://nlp.ffzg.hr/resources/corpora/setimes/"&gt;SETimes&lt;/a&gt;. The basic idea is to prepare a training data of (text, language) pairs and then train a classifier on&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Language Training Data Example" src="/images/lang_training_data.png"&gt; &lt;/p&gt;
&lt;p&gt;The benchmark shows that the pre-trained models are better than &lt;a href="https://github.com/saffsd/langid.py"&gt;langid.py&lt;/a&gt;, another popular language identification tool. Fasttext has better accuracy and also the inference time is very fast. It supports a wide variety of languages including French, German, English, Spanish,&amp;nbsp;Chinese.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Benchmarks of Fasttext vs langid" src="/images/fasttext_benchmark.png"&gt;&lt;/p&gt;
&lt;h2 id="steps"&gt;Steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install the &lt;code&gt;Fasttext&lt;/code&gt; library using&amp;nbsp;pip.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install fasttext
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;There are two versions of the pre-trained models. Choose the model which fits your memory and space&amp;nbsp;requirements:&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"&gt;lid.176.bin&lt;/a&gt;: faster and slightly more accurate but &lt;span class="caps"&gt;126MB&lt;/span&gt; in&amp;nbsp;size&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz"&gt;lid.176.ftz&lt;/a&gt;: a compressed version of the model, with a file size of&amp;nbsp;917kB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the pre-trained model from Fasttext to some location. You&amp;#8217;ll need to specify this location later in the code. In our example, we download it to the /tmp&amp;nbsp;directory. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget -O /tmp/lid.176.bin https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Now, we import fasttext and then load the model from the pretrained path we downloaded&amp;nbsp;earlier.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;fasttext&lt;/span&gt;

&lt;span class="n"&gt;PRETRAINED_MODEL_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/tmp/lid.176.bin&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fasttext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PRETRAINED_MODEL_PATH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Let&amp;#8217;s take an example sentence in French which means &amp;#8216;I eat food&amp;#8217;. To detect it&amp;#8217;s language, just pass a list of sentences to the predict function. The sentences should be in the &lt;span class="caps"&gt;UTF&lt;/span&gt;-8&amp;nbsp;format.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="French to English Translation Training Data" src="/images/french_to_english_translation.png"&gt; &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;je mange de la nourriture&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# ([[&amp;#39;__label__fr&amp;#39;]], array([[0.96568173]]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The model returns back two tuples back. One of them is an array of language labels and the other is the confidence for each sentence. Here &amp;#8216;fr&amp;#8217; is the &lt;span class="caps"&gt;ISO&lt;/span&gt; 639 code for French. The model is 96.56% confident that the language is&amp;nbsp;French.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fasttext returns the &lt;span class="caps"&gt;ISO&lt;/span&gt; code for the most probable one among the 170 languages. You can refer to the page on &lt;a href="https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes"&gt;&lt;span class="caps"&gt;ISO&lt;/span&gt; 639&lt;/a&gt; codes to find language for each&amp;nbsp;symbol.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;af als am an ar arz as ast av az azb ba bar bcl be bg bh bn bo bpy br bs bxr ca cbk ce ceb ckb co cs cv cy da de diq dsb dty dv el eml en eo es et eu fa fi fr frr fy ga gd gl gn gom gu gv he hi hif hr hsb ht hu hy ia id ie ilo io is it ja jbo jv ka kk km kn ko krc ku kv kw ky la lb lez li lmo lo lrc lt lv mai mg mhr min mk ml mn mr mrj ms mt mwl my myv mzn nah nap nds ne new nl nn no oc or os pa pam pfl pl pms pnb ps pt qu rm ro ru rue sa sah sc scn sco sd sh si sk sl so sq sr su sv sw ta te tg th tk tl tr tt tyv ug uk ur uz vec vep vi vls vo wa war wuu xal xmf yi yo yue zh
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;To programmatically convert language symbols back to the language name, you can use &lt;a href="https://pypi.org/project/pycountry/"&gt;pycountry&lt;/a&gt; package. Install the package using&amp;nbsp;pip.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;pycountry&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Now, pass the symbol to pycountry and you will get back the language&amp;nbsp;name.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pycountry&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;languages&lt;/span&gt;

&lt;span class="n"&gt;language_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;languages&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha_2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;language_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# french&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="fasttext"></category><category term="language"></category></entry><entry><title>How to Automate Manual Steps after SSH</title><link href="https://amitness.com/2019/03/automate-ssh-commands/" rel="alternate"></link><published>2019-03-31T22:08:00+05:45</published><updated>2019-03-31T22:08:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2019-03-31:/2019/03/automate-ssh-commands/</id><summary type="html">&lt;p&gt;Learn how to automate repetitive commands after connecting to a &lt;span class="caps"&gt;SSH&lt;/span&gt;&amp;nbsp;server&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently worked on a Django web application which was deployed on a Linux Server with &lt;span class="caps"&gt;SSH&lt;/span&gt; access. Deployments
were done manually and the &lt;span class="caps"&gt;CI&lt;/span&gt;/&lt;span class="caps"&gt;CD&lt;/span&gt; pipeline was still in&amp;nbsp;planning.&lt;/p&gt;
&lt;p&gt;We had to perform these tasks every time to deploy the latest&amp;nbsp;changes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;SSH&lt;/span&gt; into the&amp;nbsp;server&lt;/li&gt;
&lt;li&gt;Goto directory where the code is&amp;nbsp;present&lt;/li&gt;
&lt;li&gt;Activate Virtual&amp;nbsp;Environment&lt;/li&gt;
&lt;li&gt;Pull the latest changes on the current branch using&amp;nbsp;Git&lt;/li&gt;
&lt;li&gt;Install any newly added libraries from&amp;nbsp;requirements.txt&lt;/li&gt;
&lt;li&gt;Run migrations for the&amp;nbsp;database&lt;/li&gt;
&lt;li&gt;Run command to generate static&amp;nbsp;files&lt;/li&gt;
&lt;li&gt;Restart Nginx and&amp;nbsp;Supervisor&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I found the process repetitive and researched on whether it was possible to automate the commands I need to run
after SSHing into the&amp;nbsp;server.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh -i &lt;span class="s2"&gt;&amp;quot;webapp.pem&amp;quot;&lt;/span&gt; ubuntu@example.com
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Turns out, we can write a shell script to automate the&amp;nbsp;task.&lt;/p&gt;
&lt;h2 id="step-1"&gt;Step&amp;nbsp;1:&lt;/h2&gt;
&lt;p&gt;Create a new shell script file &lt;code&gt;deploy.sh&lt;/code&gt; with the following content. Modify it to point to your &lt;span class="caps"&gt;PEM&lt;/span&gt; file, username, and &lt;span class="caps"&gt;IP&lt;/span&gt;&amp;nbsp;address.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
ssh -i &lt;span class="s2"&gt;&amp;quot;webapp.pem&amp;quot;&lt;/span&gt; ubuntu@example.com &lt;span class="s"&gt;&amp;lt;&amp;lt; EOF&lt;/span&gt;
&lt;span class="s"&gt;    echo &amp;quot;Hello World&amp;quot;&lt;/span&gt;
&lt;span class="s"&gt;EOF&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above code prints &amp;#8216;Hello World&amp;#8217; on the remote&amp;nbsp;server.&lt;/p&gt;
&lt;h2 id="step-2"&gt;Step&amp;nbsp;2:&lt;/h2&gt;
&lt;p&gt;You can write any shell commands between the two &lt;code&gt;EOF&lt;/code&gt; and it will be run on the remote server.
Add the sequence of commands you currently run manually on the server to this&amp;nbsp;script.&lt;/p&gt;
&lt;p&gt;For the Django project, I wrote the following commands that pulls the latest code and restarts the&amp;nbsp;services.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="n"&gt;ssh&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;webapp.pem&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="nd"&gt;@example.com&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;EOF&lt;/span&gt;
&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;webapp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Switching to www-data user&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Hu&lt;/span&gt; &lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="n"&gt;bash&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Pulling Latest Changes&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;pull&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Activating Virtual Environment&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="n"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Installing any new libraries&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Migrating Database&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;manage&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="n"&gt;migrate&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Returning back to Ubuntu user&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Restarting Supervisor and Nginx&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;service&lt;/span&gt; &lt;span class="n"&gt;supervisor&lt;/span&gt; &lt;span class="n"&gt;restart&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;service&lt;/span&gt; &lt;span class="n"&gt;nginx&lt;/span&gt; &lt;span class="n"&gt;restart&lt;/span&gt;

&lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Deployment Finished&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;EOF&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="step-3"&gt;Step&amp;nbsp;3:&lt;/h2&gt;
&lt;p&gt;Run the below command to change permissions of the script and make it&amp;nbsp;executable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chmod a+x deploy.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="step-4"&gt;Step&amp;nbsp;4:&lt;/h2&gt;
&lt;p&gt;Run the script and it will perform all the&amp;nbsp;deployment.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./deploy.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This simple script has saved me a lot of time until the &lt;span class="caps"&gt;CI&lt;/span&gt;/&lt;span class="caps"&gt;CD&lt;/span&gt; process is in&amp;nbsp;place.&lt;/p&gt;</content></entry><entry><title>Django ORM if you already know SQL</title><link href="https://amitness.com/2018/10/django-orm-for-sql-users/" rel="alternate"></link><published>2018-10-31T22:16:00+05:45</published><updated>2018-10-31T22:16:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2018-10-31:/2018/10/django-orm-for-sql-users/</id><summary type="html">&lt;p&gt;If you are migrating to Django from another &lt;span class="caps"&gt;MVC&lt;/span&gt; framework, chances are you already know &lt;span class="caps"&gt;SQL&lt;/span&gt;. In this post, I will be illustrating how to use Django &lt;span class="caps"&gt;ORM&lt;/span&gt; by drawing analogies to equivalent &lt;span class="caps"&gt;SQL&lt;/span&gt;&amp;nbsp;statements.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you are migrating to Django from another &lt;span class="caps"&gt;MVC&lt;/span&gt; framework, chances are you already know &lt;span class="caps"&gt;SQL&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;In this post, I will be illustrating how to use Django &lt;span class="caps"&gt;ORM&lt;/span&gt; by drawing analogies to equivalent &lt;span class="caps"&gt;SQL&lt;/span&gt; statements. Connecting a new topic to your existing knowledge will help you learn to use the &lt;span class="caps"&gt;ORM&lt;/span&gt;&amp;nbsp;faster.&lt;/p&gt;
&lt;p&gt;Let us consider a simple base model for a person with attributes name, age, and&amp;nbsp;gender. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Person ER Diagram" src="/images/entity-diagram-django.png"&gt;&lt;/p&gt;
&lt;p&gt;To implement the above entity, we would model it as a table in &lt;span class="caps"&gt;SQL&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="nb"&gt;varchar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;gender&lt;/span&gt; &lt;span class="nb"&gt;varchar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The same table is modeled in Django as a class which inherits from the base Model class. The &lt;span class="caps"&gt;ORM&lt;/span&gt; creates the equivalent table under the&amp;nbsp;hood.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CharField&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blank&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IntegerField&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;gender&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CharField&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blank&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The most used data types&amp;nbsp;are:  &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Django&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;INT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;IntegerField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;VARCHAR(n)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;CharField(max_length=n)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;TEXT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;TextField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;FLOAT(n)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;FloatField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;DATE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;DateField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;TIME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;TimeField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;DATETIME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;DateTimeField()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The various queries we can use&amp;nbsp;are:  &lt;/p&gt;
&lt;h2 id="select-statement"&gt;&lt;span class="caps"&gt;SELECT&lt;/span&gt;&amp;nbsp;Statement&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Fetch all rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;persons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;person&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;persons&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Fetch specific columns&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;only&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Fetch distinct rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;DISTINCT&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distinct&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Fetch specific number of rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;LIMIT&lt;/span&gt; &lt;span class="caps"&gt;AND&lt;/span&gt; &lt;span class="caps"&gt;OFFSET&lt;/span&gt; keywords&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;OFFSET&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="where-clause"&gt;&lt;span class="caps"&gt;WHERE&lt;/span&gt;&amp;nbsp;Clause&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Filter by single column&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Filter by comparison operators&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__gt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__gte&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__lt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__lte&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exclude&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;BETWEEN&lt;/span&gt; Clause&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt; 
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="k"&gt;BETWEEN&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;LIKE&lt;/span&gt; operator&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%A%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="nb"&gt;binary&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%A%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;A%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="nb"&gt;binary&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;A%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="nb"&gt;binary&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__icontains&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__contains&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__istartswith&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__startswith&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__iendswith&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name__endswith&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;IN&lt;/span&gt; operator&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id__in&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="and-or-and-not-operators"&gt;&lt;span class="caps"&gt;AND&lt;/span&gt;, &lt;span class="caps"&gt;OR&lt;/span&gt; and &lt;span class="caps"&gt;NOT&lt;/span&gt;&amp;nbsp;Operators&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age__gt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;OR&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Q&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__gt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exclude&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="null-values"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&amp;nbsp;Values&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__isnull&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__isnull&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Alternate approach&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exclude&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="order-by-keyword"&gt;&lt;span class="caps"&gt;ORDER&lt;/span&gt; &lt;span class="caps"&gt;BY&lt;/span&gt;&amp;nbsp;Keyword&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ascending Order&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;order&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;order_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Descending Order&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;order_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="insert-into-statement"&gt;&lt;span class="caps"&gt;INSERT&lt;/span&gt; &lt;span class="caps"&gt;INTO&lt;/span&gt;&amp;nbsp;Statement&lt;/h2&gt;
&lt;p&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;INSERT&lt;/span&gt; &lt;span class="k"&gt;INTO&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;VALUES&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Jack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;23&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;jack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="update-statement"&gt;&lt;span class="caps"&gt;UPDATE&lt;/span&gt;&amp;nbsp;Statement&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Update single row&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;UPDATE&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;SET&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;person&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Update multiple rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;UPDATE&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;SET&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;

&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="delete-statement"&gt;&lt;span class="caps"&gt;DELETE&lt;/span&gt;&amp;nbsp;Statement&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Delete all rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;DELETE&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Delete specific rows&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;DELETE&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age__lt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="aggregation"&gt;Aggregation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;MIN&lt;/span&gt; Function&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;MIN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Min&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age__min&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;MAX&lt;/span&gt; Function&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;MAX&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age__max&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;AVG&lt;/span&gt; Function&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;AVG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Avg&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Avg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age__avg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;SUM&lt;/span&gt; Function&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;SUM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Sum&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age__sum&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5050&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;COUNT&lt;/span&gt; Function&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="group-by-statement"&gt;&lt;span class="caps"&gt;GROUP&lt;/span&gt; &lt;span class="caps"&gt;BY&lt;/span&gt;&amp;nbsp;Statement&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Count of Person by gender&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="having-clause"&gt;&lt;span class="caps"&gt;HAVING&lt;/span&gt;&amp;nbsp;Clause&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Count of Person by gender if number of person is greater than 1&lt;/strong&gt; &lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Person&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;gender&lt;/span&gt;
&lt;span class="k"&gt;HAVING&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gender&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count__gt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="joins"&gt;&lt;span class="caps"&gt;JOINS&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Consider a foreign key relationship between books and&amp;nbsp;publisher.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Publisher&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CharField&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Book&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;publisher&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ForeignKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Publisher&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;on_delete&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CASCADE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Fetch publisher name for a book&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;Publisher&lt;/span&gt;
&lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publisher_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Publisher&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;book&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_related&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;publisher&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;book&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publisher&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Fetch books which have specific publisher&lt;/strong&gt;&lt;br&gt;
&lt;span class="caps"&gt;SQL&lt;/span&gt;:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;Book&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publisher_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Django:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;publisher&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Publisher&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prefetch_related&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;book_set&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;books&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;publisher&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;book_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="django"></category><category term="orm"></category></entry><entry><title>Shutdown Ubuntu With A KeyboardÂ Shortcut</title><link href="https://amitness.com/2015/06/ubuntu-keyboard-shortcut/" rel="alternate"></link><published>2015-06-16T08:00:00+05:45</published><updated>2016-10-17T08:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2015-06-16:/2015/06/ubuntu-keyboard-shortcut/</id><summary type="html">&lt;p&gt;In Windows, we can use Alt+F4 keyboard shortcut to shutdown. But Linux doesnât have such feature out of the box. After switching to Ubuntu, I struggled trying to make a keyboard shortcut for shutting down the&amp;nbsp;computer.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In Windows, we can use Alt+F4 keyboard shortcut to shutdown. But Linux doesnât have such feature out of the box. After switching to Ubuntu, I struggled trying to make a keyboard shortcut for shutting down the&amp;nbsp;computer. &lt;/p&gt;
&lt;p&gt;So I started reading about the packages related to shutdown and discovered a method that works flawlessly. We utilize a package called &lt;em&gt;shutdown&lt;/em&gt; thatâs present by default in the /sbin&amp;nbsp;directory.&lt;/p&gt;
&lt;h2 id="steps"&gt;Steps:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open a terminal and enter the following command.  You will be asked for the&amp;nbsp;password.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo chmod u+s /sbin/shutdown
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Then goto System Settings &amp;gt; Keyboard and in the shortcuts tab, click Custom&amp;nbsp;Shortcuts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Keyboard Shortcuts" class="img-center" src="/images/keyboard-shortcuts.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Then click the âAdd custom shortcutâ button and a popup will open. In it add name as &lt;em&gt;âShutdownâ&lt;/em&gt; and command as &lt;strong&gt;âshutdown -h nowâ&lt;/strong&gt; . Then click&amp;nbsp;add.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Custom Shortcut Menu" class="img-center" src="/images/custom-shortcut.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After adding, you will get a list of shortcuts as shown below. In that click shutdown and below it, there will be three unassigned. Click the first unassigned and it will change into &lt;em&gt;âPick an acceleratorâ&lt;/em&gt;. Then click &lt;code&gt;Ctrl+Alt+K&lt;/code&gt; at the same time. This will be our shortcut for&amp;nbsp;shutdown.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Key Binding Menu" class="img-center" src="/images/keyboard-binding.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can make a shortcut for restart as well, follow the same tutorial except in step 3, use code &lt;em&gt;shutdown &lt;strong&gt;-r&lt;/strong&gt; now&lt;/em&gt;&amp;nbsp;.&lt;/p&gt;
&lt;p&gt;You have a fully functioning keyboard shortcut to shutdown Linux just like Windows. Press Ctrl+Alt+K and your system is off. Please let me know if it worked for you in the&amp;nbsp;comments.&lt;/p&gt;</content><category term="ubuntu"></category><category term="keyboard shortcut"></category><category term="linux"></category></entry><entry><title>How to Reduce Data Usage While BrowsingÂ Internet</title><link href="https://amitness.com/2015/06/save-data/" rel="alternate"></link><published>2015-06-15T08:00:00+05:45</published><updated>2016-10-14T08:00:00+05:45</updated><author><name>Amit Chaudhary</name></author><id>tag:amitness.com,2015-06-15:/2015/06/save-data/</id><summary type="html">&lt;p&gt;According to the &lt;span class="caps"&gt;HTTP&lt;/span&gt; Archive, the average webpage size has increased by 50 % per year. When you donât have unlimited internet, using the Internet without crossing data cap seems an impossible task. But you can browse the web consuming less&amp;nbsp;data.&lt;/p&gt;</summary><content type="html">&lt;p&gt;According to the &lt;span class="caps"&gt;HTTP&lt;/span&gt; Archive, the average webpage size has increased by 50 % per year. When you donât have unlimited internet, using the Internet without crossing data cap seems an impossible task. But you can browse the web consuming less&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;I use a volume based Internet connection of 40 &lt;span class="caps"&gt;GB&lt;/span&gt; per month. I follow some methods to reduce the data consumption while using&amp;nbsp;Internet. &lt;/p&gt;
&lt;h3 id="steps"&gt;&lt;span class="caps"&gt;STEPS&lt;/span&gt;:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.&amp;nbsp;Browser:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Letâs start with the browser. The browser is our gateway to the Internet. I use Google Chrome as my primary internet browser. Google has an official extension for Chrome that compresses the data for &lt;span class="caps"&gt;HTTP&lt;/span&gt; websites so that it becomes faster and uses less data. The extension is called &lt;em&gt;Data Saver&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Download it from &lt;a href="https://chrome.google.com/webstore/detail/data-saver-beta/pfmgfdlgomnbgkofeojodiodmgpgmkac?hl=en"&gt;here&lt;/a&gt; and once added, you should see a icon added beside the menu in chrome. Click it and select Turn on data saver&amp;nbsp;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Data Saver Screenshot 1" class="img-center" src="https://lh4.googleusercontent.com/4-Up5b6TS1Egr7MPHPUPj-T5thIUnuDV_HP15AgoS0laHv7nITjhZsOg9PlCOHLvCZjJWj4R9g=s640-h400-e365-rw"&gt;
&lt;img alt="Data Saver Screenshot 2" class="img-center" src="https://lh5.googleusercontent.com/xVLJ1HZBbggSQtOuU1Cz4wn8AM22y7lNec07j9oFTwCIBU0mfUDXbGeaDlA6urfe-WhVuizZCQ=s640-h400-e365-rw"&gt;&lt;/p&gt;
&lt;p&gt;From now on, Chrome should start compressing the site elements and images by passing them through google servers. In my testing, I saved up to 20% data in a&amp;nbsp;month. &lt;/p&gt;
&lt;p&gt;Note: &lt;em&gt;This doesnât work on secure pages and in incognito&amp;nbsp;mode.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. YouTube&amp;nbsp;Settings:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is a hidden setting in YouTube that plays videos in 360p quality by default. 360p is both clear as well as data friendly quality for watching&amp;nbsp;video.&lt;/p&gt;
&lt;p&gt;To access the setting, go to https://www.youtube.com/account_playback and tick âI have a slow connection. Never play higher-quality video.â in Video playback quality. From now on, Videos will default to&amp;nbsp;360p.&lt;/p&gt;
&lt;p&gt;Also, YouTube has an experimental video player that uses &lt;span class="caps"&gt;HTML5&lt;/span&gt; instead of Flash to play videos. It can play videos with an average bandwidth reduction of 35 percent. To enable it, go to TestTube and on the bottom, click âGet the playerâ under Try out the Redesigned YouTube&amp;nbsp;Player.&lt;/p&gt;
&lt;p&gt;&lt;img alt="YouTube HTML5 Player" class="img-center" src="/images/youtube_player1.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Run Plugins on&amp;nbsp;Demand:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Chrome automatically plays flash ads and videos leading to higher data usage. You can stop this&amp;nbsp;behaviour.&lt;/p&gt;
&lt;p&gt;Go to settings through menu and then&amp;nbsp;select &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Show advanced settings &amp;gt; Privacy &amp;gt; Content settings. &amp;gt; Plug-ins &amp;gt; Click to&amp;nbsp;play &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From now on, video advertisement wonât be played automatically, thus saving a lot of&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;I hope these tips will help you lower data usage and be under your data cap. If you have any other tips, do leave them as&amp;nbsp;comments.&lt;/p&gt;</content><category term="chrome"></category><category term="data usage"></category></entry></feed>